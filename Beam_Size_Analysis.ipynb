{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c41db38",
   "metadata": {},
   "source": [
    "# Analyzing the Distances Between Beams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7caf2457",
   "metadata": {},
   "source": [
    "Start off by importing any necessary packages. Check the README for the versions of each of the packages being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7908523a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from tabulate import tabulate\n",
    "from astropy.time import Time\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82d6f1a",
   "metadata": {},
   "source": [
    "Open up the .pickle files. The 4_beams.pkl file has all of the hits that are present in 4 of the beams in a given field of view. The same is true for 5_beams.pkl but the hit is present in 5 of the beams. However, there is a caveat here in that all of the hits that were missing an incoherent beam were excluded. These were assumed to be low intensity RFI, which when the average was taken to create the incoherent beam were excluded but were still classified as being hits in 4-5 of the coherent beams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b1b53f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45728, 24)\n",
      "(38604, 24)\n",
      "(73840, 24)\n",
      "(181150, 24)\n"
     ]
    }
   ],
   "source": [
    "with open('../../2_beams_coherent.pkl', 'rb') as f:\n",
    "    hit_2 = pickle.load(f)\n",
    "print(hit_2.shape)\n",
    "file_path_2 = hit_2[\"file_path\"]\n",
    "unique_file_path_2 = np.unique(file_path_2) #the array of unique fields of view\n",
    "\n",
    "with open('../../3_beams.pkl', 'rb') as f:\n",
    "    hit_3 = pickle.load(f)\n",
    "print(hit_3.shape)\n",
    "file_path_3 = hit_3[\"file_path\"]\n",
    "unique_file_path_3 = np.unique(file_path_3) #the array of unique fields of view\n",
    "\n",
    "with open('../../4_beams.pkl', 'rb') as f:\n",
    "    hit_4 = pickle.load(f)\n",
    "print(hit_4.shape)\n",
    "file_path_4 = hit_4[\"file_path\"]\n",
    "unique_file_path_4 = np.unique(file_path_4) #the array of unique fields of view\n",
    "\n",
    "with open('../../5_beams.pkl', 'rb') as f:\n",
    "    hit_5 = pickle.load(f)\n",
    "print(hit_5.shape)\n",
    "file_path_5 = hit_5[\"file_path\"]\n",
    "unique_file_path_5 = np.unique(file_path_5) #the array of unique fields of view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc953b0d",
   "metadata": {},
   "source": [
    "This data was taken at S band with the VLA in the B configuration. This would mean that the beam size should be 2.1 arcseconds. So here's my plan:\n",
    "\n",
    "- Clump together each hit \n",
    "- Find the distances between each of the coordinates in RA and DEC\n",
    "- Convert these distances to arcseconds\n",
    "\n",
    "Now there a few other things to consider here. The center of the incoherent beam is usually offset from where all of the coherent beams are, so the distances should be calculated for each of the points aside from the incoherent beam so that it does not cause issues with the distances. We will then filter out any of them that have a distance greater than 6.3 arcseconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d9b73ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0 4.0\n",
      "0.5621356454823611\n",
      "-5.987875597742031\n",
      "6.014204075183711\n"
     ]
    }
   ],
   "source": [
    "right_ascension = hit_5[\"ra\"]\n",
    "declination = hit_5[\"dec\"]\n",
    "beam = hit_5[\"beam\"]\n",
    "\n",
    "print(beam[2], beam[1])\n",
    "print((right_ascension[1]-right_ascension[2])*math.pi*3600/180)\n",
    "print((declination[1]-declination[2])*math.pi*3600/180)\n",
    "print(math.sqrt(((right_ascension[1]-right_ascension[2])*math.pi*3600/180)**2+((declination[1]-declination[2])*math.pi*3600/180)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db94df1",
   "metadata": {},
   "source": [
    "So I'm going to make a for loop that goes through all of the clumps, and then does the above calculation for each of the combinations, except for the coherent beam. To do this, once I pull the clump, I'll sort it by the beam and then only look at the combinations that occur within beams 0-4. I will append all of the distances to an array for the specific clump. Then if any of the values in the array are greater than 6.3, the clump will not get appended to the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a39520f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36230/36230 [01:52<00:00, 322.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87350, 24)\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.DataFrame({\"file_path\":[],\n",
    "                    \"hit_file_enumeration\":[],\n",
    "                    \"signal_frequency\":[],\n",
    "                    \"signal_index\":[],\n",
    "                    \"signal_driftSteps\":[],\n",
    "                    \"signal_driftRate\":[],\n",
    "                    \"signal_snr\":[],\n",
    "                    \"signal_coarseChannel\":[],\n",
    "                    \"signal_numTimesteps\":[],\n",
    "                    \"signal_power\":[],\n",
    "                    \"signal_incoherentPower\":[],\n",
    "                    \"sourceName\":[],\n",
    "                    \"fch1\":[],\n",
    "                    \"foff\":[],\n",
    "                    \"tstart\":[],\n",
    "                    \"tsamp\":[],\n",
    "                    \"ra\":[],\n",
    "                    \"dec\":[],\n",
    "                    \"telescopeId\":[],\n",
    "                    \"numTimesteps\":[],\n",
    "                    \"numChannels\":[],\n",
    "                    \"coarseChannel\":[],\n",
    "                    \"startChannel\":[],\n",
    "                    \"beam\":[]})\n",
    "\n",
    "for i in tqdm(range(int(len(file_path_5)/5))):\n",
    "    data_fov_subset = hit_5.loc[i*5:(i*5)+4] #select each subset    \n",
    "    #It is already organized by frequency so we don't need to sort by frequency, but still do that so that it can be sorted by \n",
    "    #frequency and then by beam\n",
    "    data_fov_subset = data_fov_subset.sort_values(by = [\"signal_frequency\", \"beam\"])\n",
    "\n",
    "    right_ascension = np.array(data_fov_subset[\"ra\"]) #define the column for right ascension\n",
    "    declination = np.array(data_fov_subset[\"dec\"]) #define the column for the declination\n",
    "    beam = np.array(data_fov_subset[\"beam\"])\n",
    "    \n",
    "    distances = []\n",
    "    for j in range(len(right_ascension)-1):\n",
    "        for k in range(len(right_ascension)-1): #Have it loop over the clump twice to get all of the combinations\n",
    "            #This will be very oversampled, but it doesn't matter too much because I only care about the maximum value\n",
    "            \n",
    "            ra_diff = (right_ascension[j]-right_ascension[k])*math.pi*3600/180 \n",
    "            #Difference between the ra coordinates in arcseconds\n",
    "            \n",
    "            dec_diff = (declination[j]-declination[k])*math.pi*3600/180\n",
    "            #Difference between the dec coordinates in arcseconds\n",
    "            \n",
    "            dist = math.sqrt(ra_diff**2+dec_diff**2)\n",
    "            #Distance formula\n",
    "            \n",
    "            distances.append(dist)\n",
    "            #Append all of the distances to the list\n",
    "    \n",
    "    if np.max(distances) < 6.3:\n",
    "        #Want to make sure that all of the sources are within 3 beams of each other. With a beam size of 2.1 arcseconds, I want\n",
    "        #them to be at most 6.3 arcseconds away. If even one of the distances is greater than 6.3, then the entire clump is not\n",
    "        #appended\n",
    "        \n",
    "        appending_rows = data_fov_subset\n",
    "        df2 = df2.append(appending_rows, ignore_index = True)\n",
    "    else:\n",
    "        continue    \n",
    "\n",
    "with open('../../beam_separation_5_hits.pkl', 'wb') as f:  # open a text file\n",
    "    pickle.dump(df2, f) # serialize the list\n",
    "f.close()\n",
    "\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd49505f",
   "metadata": {},
   "source": [
    "So I've taken a look now to see the separations of the hits that are present in 5 beams. I'm going to repeat the process for the hits that did have an incoherent beam and were present in 4, 3, and 2 beams. I am ending each cell by saving the resulting dataframe to a .pickle file and printing out the shape so that I can see how many hits are remaining.\n",
    "\n",
    "This cell is showing the code to find the spacing for the hits that were observed in four beams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08e37c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18460/18460 [00:33<00:00, 546.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31544, 24)\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.DataFrame({\"file_path\":[],\n",
    "                    \"hit_file_enumeration\":[],\n",
    "                    \"signal_frequency\":[],\n",
    "                    \"signal_index\":[],\n",
    "                    \"signal_driftSteps\":[],\n",
    "                    \"signal_driftRate\":[],\n",
    "                    \"signal_snr\":[],\n",
    "                    \"signal_coarseChannel\":[],\n",
    "                    \"signal_numTimesteps\":[],\n",
    "                    \"signal_power\":[],\n",
    "                    \"signal_incoherentPower\":[],\n",
    "                    \"sourceName\":[],\n",
    "                    \"fch1\":[],\n",
    "                    \"foff\":[],\n",
    "                    \"tstart\":[],\n",
    "                    \"tsamp\":[],\n",
    "                    \"ra\":[],\n",
    "                    \"dec\":[],\n",
    "                    \"telescopeId\":[],\n",
    "                    \"numTimesteps\":[],\n",
    "                    \"numChannels\":[],\n",
    "                    \"coarseChannel\":[],\n",
    "                    \"startChannel\":[],\n",
    "                    \"beam\":[]})\n",
    "\n",
    "for i in tqdm(range(int(len(file_path_4)/4))):\n",
    "    data_fov_subset = hit_4.loc[i*4:(i*4)+3] #select each subset    \n",
    "    #It is already organized by frequency so we don't need to sort by frequency, but still do that so that it can be sorted by \n",
    "    #frequency and then by beam\n",
    "    data_fov_subset = data_fov_subset.sort_values(by = [\"signal_frequency\", \"beam\"])\n",
    "\n",
    "    right_ascension = np.array(data_fov_subset[\"ra\"]) #define the column for right ascension\n",
    "    declination = np.array(data_fov_subset[\"dec\"]) #define the column for the declination\n",
    "    beam = np.array(data_fov_subset[\"beam\"])\n",
    "    \n",
    "    distances = []\n",
    "    for j in range(len(right_ascension)-1):\n",
    "        for k in range(len(right_ascension)-1): #Have it loop over the clump twice to get all of the combinations\n",
    "            #This will be very oversampled, but it doesn't matter too much because I only care about the maximum value\n",
    "            \n",
    "            ra_diff = (right_ascension[j]-right_ascension[k])*math.pi*3600/180 \n",
    "            #Difference between the ra coordinates in arcseconds\n",
    "            \n",
    "            dec_diff = (declination[j]-declination[k])*math.pi*3600/180\n",
    "            #Difference between the dec coordinates in arcseconds\n",
    "            \n",
    "            dist = math.sqrt(ra_diff**2+dec_diff**2)\n",
    "            #Distance formula\n",
    "            \n",
    "            distances.append(dist)\n",
    "            #Append all of the distances to the list\n",
    "    \n",
    "    if np.max(distances) < 6.3:\n",
    "        #Want to make sure that all of the sources are within 3 beams of each other. With a beam size of 2.1 arcseconds, I want\n",
    "        #them to be at most 6.3 arcseconds away. If even one of the distances is greater than 6.3, then the entire clump is not\n",
    "        #appended\n",
    "        \n",
    "        appending_rows = data_fov_subset\n",
    "        df2 = df2.append(appending_rows, ignore_index = True)\n",
    "    else:\n",
    "        continue    \n",
    "\n",
    "with open('../../beam_separation_4_hits.pkl', 'wb') as f:  # open a text file\n",
    "    pickle.dump(df2, f) # serialize the list\n",
    "f.close()\n",
    "\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db2f7bd",
   "metadata": {},
   "source": [
    "Here are the hits that were observed in 3 beams. It is just looking at the distances between the two coherent beams and keeping the hits where the distance is a maximum of 6.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b549e7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12868/12868 [00:26<00:00, 491.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25734, 24)\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.DataFrame({\"file_path\":[],\n",
    "                    \"hit_file_enumeration\":[],\n",
    "                    \"signal_frequency\":[],\n",
    "                    \"signal_index\":[],\n",
    "                    \"signal_driftSteps\":[],\n",
    "                    \"signal_driftRate\":[],\n",
    "                    \"signal_snr\":[],\n",
    "                    \"signal_coarseChannel\":[],\n",
    "                    \"signal_numTimesteps\":[],\n",
    "                    \"signal_power\":[],\n",
    "                    \"signal_incoherentPower\":[],\n",
    "                    \"sourceName\":[],\n",
    "                    \"fch1\":[],\n",
    "                    \"foff\":[],\n",
    "                    \"tstart\":[],\n",
    "                    \"tsamp\":[],\n",
    "                    \"ra\":[],\n",
    "                    \"dec\":[],\n",
    "                    \"telescopeId\":[],\n",
    "                    \"numTimesteps\":[],\n",
    "                    \"numChannels\":[],\n",
    "                    \"coarseChannel\":[],\n",
    "                    \"startChannel\":[],\n",
    "                    \"beam\":[]})\n",
    "\n",
    "for i in tqdm(range(int(len(file_path_3)/3))):\n",
    "    data_fov_subset = hit_3.loc[i*3:(i*3)+2] #select each subset    \n",
    "    #It is already organized by frequency so we don't need to sort by frequency, but still do that so that it can be sorted by \n",
    "    #frequency and then by beam\n",
    "    data_fov_subset = data_fov_subset.sort_values(by = [\"signal_frequency\", \"beam\"])\n",
    "\n",
    "    right_ascension = np.array(data_fov_subset[\"ra\"]) #define the column for right ascension\n",
    "    declination = np.array(data_fov_subset[\"dec\"]) #define the column for the declination\n",
    "    beam = np.array(data_fov_subset[\"beam\"])\n",
    "    \n",
    "    distances = []\n",
    "    for j in range(len(right_ascension)-1):\n",
    "        for k in range(len(right_ascension)-1): #Have it loop over the clump twice to get all of the combinations\n",
    "            #This will be very oversampled, but it doesn't matter too much because I only care about the maximum value\n",
    "            \n",
    "            ra_diff = (right_ascension[j]-right_ascension[k])*math.pi*3600/180 \n",
    "            #Difference between the ra coordinates in arcseconds\n",
    "            \n",
    "            dec_diff = (declination[j]-declination[k])*math.pi*3600/180\n",
    "            #Difference between the dec coordinates in arcseconds\n",
    "            \n",
    "            dist = math.sqrt(ra_diff**2+dec_diff**2)\n",
    "            #Distance formula\n",
    "            \n",
    "            distances.append(dist)\n",
    "            #Append all of the distances to the list\n",
    "    \n",
    "    if np.max(distances) < 6.3:\n",
    "        #Want to make sure that all of the sources are within 3 beams of each other. With a beam size of 2.1 arcseconds, I want\n",
    "        #them to be at most 6.3 arcseconds away. If even one of the distances is greater than 6.3, then the entire clump is not\n",
    "        #appended\n",
    "        \n",
    "        appending_rows = data_fov_subset\n",
    "        df2 = df2.append(appending_rows, ignore_index = True)\n",
    "    else:\n",
    "        continue    \n",
    "\n",
    "with open('../../beam_separation_3_hits.pkl', 'wb') as f:  # open a text file\n",
    "    pickle.dump(df2, f) # serialize the list\n",
    "f.close()\n",
    "\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c120f09d",
   "metadata": {},
   "source": [
    "This one is a little bit different than the previous three cells. Instead of having the pairs of an incoherent and a coherent beam, this has pairs of coherent beams where there was no corresponding incoherent beam for the hit. The idea for these hits is that it was a localized signal but at a very low intensity where it got washed out in the averaging to create the incoherent beam. If anything, these could be the more interesting things to take a look at. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5e4bc457",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22864/22864 [00:54<00:00, 416.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37328, 24)\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.DataFrame({\"file_path\":[],\n",
    "                    \"hit_file_enumeration\":[],\n",
    "                    \"signal_frequency\":[],\n",
    "                    \"signal_index\":[],\n",
    "                    \"signal_driftSteps\":[],\n",
    "                    \"signal_driftRate\":[],\n",
    "                    \"signal_snr\":[],\n",
    "                    \"signal_coarseChannel\":[],\n",
    "                    \"signal_numTimesteps\":[],\n",
    "                    \"signal_power\":[],\n",
    "                    \"signal_incoherentPower\":[],\n",
    "                    \"sourceName\":[],\n",
    "                    \"fch1\":[],\n",
    "                    \"foff\":[],\n",
    "                    \"tstart\":[],\n",
    "                    \"tsamp\":[],\n",
    "                    \"ra\":[],\n",
    "                    \"dec\":[],\n",
    "                    \"telescopeId\":[],\n",
    "                    \"numTimesteps\":[],\n",
    "                    \"numChannels\":[],\n",
    "                    \"coarseChannel\":[],\n",
    "                    \"startChannel\":[],\n",
    "                    \"beam\":[]})\n",
    "\n",
    "for i in tqdm(range(int(len(file_path_2)/2))):\n",
    "    data_fov_subset = hit_2.loc[i*2:(i*2)+1] #select each subset    \n",
    "    #It is already organized by frequency so we don't need to sort by frequency, but still do that so that it can be sorted by \n",
    "    #frequency and then by beam\n",
    "    data_fov_subset = data_fov_subset.sort_values(by = [\"signal_frequency\", \"beam\"])\n",
    "\n",
    "    right_ascension = np.array(data_fov_subset[\"ra\"]) #define the column for right ascension\n",
    "    declination = np.array(data_fov_subset[\"dec\"]) #define the column for the declination\n",
    "    beam = np.array(data_fov_subset[\"beam\"])\n",
    "    \n",
    "    distances = []\n",
    "    for j in range(len(right_ascension)):\n",
    "        for k in range(len(right_ascension)): #Have it loop over the clump twice to get all of the combinations\n",
    "            #This will be very oversampled, but it doesn't matter too much because I only care about the maximum value\n",
    "            \n",
    "            ra_diff = (right_ascension[j]-right_ascension[k])*math.pi*3600/180 \n",
    "            #Difference between the ra coordinates in arcseconds\n",
    "            \n",
    "            dec_diff = (declination[j]-declination[k])*math.pi*3600/180\n",
    "            #Difference between the dec coordinates in arcseconds\n",
    "            \n",
    "            dist = math.sqrt(ra_diff**2+dec_diff**2)\n",
    "            #Distance formula\n",
    "            \n",
    "            distances.append(dist)\n",
    "            #Append all of the distances to the list\n",
    "    \n",
    "    if np.max(distances) < 6.3:\n",
    "        #Want to make sure that all of the sources are within 3 beams of each other. With a beam size of 2.1 arcseconds, I want\n",
    "        #them to be at most 6.3 arcseconds away. If even one of the distances is greater than 6.3, then the entire clump is not\n",
    "        #appended\n",
    "        \n",
    "        appending_rows = data_fov_subset\n",
    "        df2 = df2.append(appending_rows, ignore_index = True)\n",
    "    else:\n",
    "        continue    \n",
    "\n",
    "with open('../../beam_separation_2_hits.pkl', 'wb') as f:  # open a text file\n",
    "    pickle.dump(df2, f) # serialize the list\n",
    "f.close()\n",
    "\n",
    "print(df2.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
